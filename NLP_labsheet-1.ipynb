{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f812ab87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ananthan2k/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ananthan2k/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/ananthan2k/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f46397d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"Natural language processing makes it possible for computers to  understand  the  human  language. In  natural \n",
    "language processing, human language is separated into fragments so that the grammatical structure of\n",
    "sentences and the meaning of words can be analysedand understood in context. This helps computers read and\n",
    "understand spoken or written text in the same way as humans.I  am  studying  Natural LanguageProcessing  at \n",
    "Amrita University.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b71d31a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing makes it possible for computers to  understand  the  human  language. In  natural \n",
      "language processing, human language is separated into fragments so that the grammatical structure of\n",
      "sentences and the meaning of words can be analysedand understood in context. This helps computers read and\n",
      "understand spoken or written text in the same way as humans.I  am  studying  Natural LanguageProcessing  at \n",
      "Amrita University.\n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c776394f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', 'makes', 'it', 'possible', 'for', 'computers', 'to', 'understand', 'the', 'human', 'language.', 'In', 'natural', 'language', 'processing,', 'human', 'language', 'is', 'separated', 'into', 'fragments', 'so', 'that', 'the', 'grammatical', 'structure', 'of', 'sentences', 'and', 'the', 'meaning', 'of', 'words', 'can', 'be', 'analysedand', 'understood', 'in', 'context.', 'This', 'helps', 'computers', 'read', 'and', 'understand', 'spoken', 'or', 'written', 'text', 'in', 'the', 'same', 'way', 'as', 'humans.I', 'am', 'studying', 'Natural', 'LanguageProcessing', 'at', 'Amrita', 'University.']\n"
     ]
    }
   ],
   "source": [
    "sentence = sentence.split()\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87328148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it exists in the text\n"
     ]
    }
   ],
   "source": [
    "query = \"language\"\n",
    "if query in sentence:\n",
    "    print(\"it exists in the text\")\n",
    "else:\n",
    "    print(\"It doesn't exit in the text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b96328e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "query_2 = \"human\"\n",
    "print(\"The index of the word human is :\",sentence.index(query_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4b00a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The position of the word -possible- is:  6\n"
     ]
    }
   ],
   "source": [
    "query_3 = \"possible\"\n",
    "print(\"The position of the word -possible- is: \",sentence.index(query_3)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28fbe302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The third word of the sentence is: processing\n"
     ]
    }
   ],
   "source": [
    "print(\"The third word of the sentence is:\",sentence[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13511b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Natural language processing makes it possible for computers to  understand  the  human  language. In  natural \n",
    "language processing, human language is separated into fragments so that the grammatical structure of\n",
    "sentences and the meaning of words can be analysedand understood in context. This helps computers read and\n",
    "understand spoken or written text in the same way as humans.I  am  studying  Natural LanguageProcessing  at \n",
    "Amrita University.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5701742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of lines in the sentence is:  5\n"
     ]
    }
   ],
   "source": [
    "print(\"The no of lines in the sentence is: \", len(text.split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd06ed91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of lins in the sentence are: 4\n"
     ]
    }
   ],
   "source": [
    "pattern = \"([\\.])+\"\n",
    "lines = re.findall(pattern, text)\n",
    "print(\"The number of lins in the sentence are:\", len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "602673a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of words in the sentence is  64\n"
     ]
    }
   ],
   "source": [
    "print(\"The no of words in the sentence is \",len(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9892adf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of characters in the sentence is:  372\n"
     ]
    }
   ],
   "source": [
    "pattern = \"([A-Za-z\\S])\"\n",
    "characters = re.findall(pattern, text)\n",
    "print(\"The number of characters in the sentence is: \", len(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7f127efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = \"Natural language processing makes it possible for computers to  understand  the  human  language. In  natural language processing, human language is separated into fragments so that the grammatical structure ofsentences and the meaning of words can be analysedand understood in context. This helps computers read andunderstand spoken or written text in the same way as humans. I  am  studying  Natural Language Processing  at Amrita University.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b6574388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(text):\n",
    "    print(type(text))\n",
    "    stemm_snow = SnowballStemmer(\"english\")\n",
    "    lem = WordNetLemmatizer()\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = re.sub(r\"[0-9]\", \"\", text)\n",
    "    text = text.lower()\n",
    "    text = word_tokenize(text)\n",
    "    text = [stemm_snow.stem(word) for word in text]\n",
    "    text = [lem.lemmatize(word) for word in text]\n",
    "    text = [char for char in text if char not in string.punctuation]\n",
    "    text = [word for word in text if word not in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3e3e332e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural language processing makes it possible ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts\n",
       "0  Natural language processing makes it possible ..."
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##make it into a dataframe for more flexibility\n",
    "docs_df = pd.DataFrame({\"texts\":[texts]})\n",
    "docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "325629cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "docs_df['texts'] = docs_df['texts'].apply(preProcessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6cb6d3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    natur languag process make possibl comput unde...\n",
       "Name: texts, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df['texts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d1548b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "### to make vocabulary\n",
    "sentences = docs_df['texts']\n",
    "from nltk.probability import FreqDist\n",
    "vocabs = []\n",
    "for sentence in sentences:\n",
    "    word_dist = FreqDist()\n",
    "    # update with news words frequency on each iteration\n",
    "    word_dist.update(sentence.split())\n",
    "    vocabs.append(word_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d176c7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cab4711b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FreqDist({'languag': 5, 'natur': 3, 'process': 3, 'human': 3, 'comput': 2, 'make': 1, 'possibl': 1, 'understand': 1, 'separ': 1, 'fragment': 1, ...})]\n"
     ]
    }
   ],
   "source": [
    "print(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81812daa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
