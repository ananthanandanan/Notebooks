{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "996d09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isdir\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "from torch import tensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "import timm\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4182a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = Path(\".\")\n",
    "IMAGENET_MEAN = tensor([.485, .456, .406])\n",
    "IMAGENET_STD = tensor([.229, .224, .225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "93ef2f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvtec_classes():\n",
    "    return [\"bottle\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3959e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVTecDataset:\n",
    "    def __init__(self, cls : str, size : int = 224):\n",
    "        self.cls = cls\n",
    "        self.size = size\n",
    "        \n",
    "        self.train_ds = MVTecTrainDataset(cls, size)\n",
    "        self.test_ds = MVTecTestDataset(cls, size)\n",
    "        \n",
    "    def get_datasets(self):\n",
    "        return self.train_ds, self.test_ds\n",
    "\n",
    "    def get_dataloaders(self):\n",
    "        return DataLoader(self.train_ds), DataLoader(self.test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "821d6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVTecTrainDataset(ImageFolder):\n",
    "    def __init__(self, cls : str, size : int):\n",
    "        super().__init__(\n",
    "            root= DATASETS_PATH / cls / \"train\",\n",
    "            transform=transforms.Compose([\n",
    "                transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "                transforms.CenterCrop(size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "            ])\n",
    "        )\n",
    "        self.cls = cls\n",
    "        self.size = size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "69e9b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVTecTestDataset(ImageFolder):\n",
    "    def __init__(self, cls : str, size : int):\n",
    "        super().__init__(\n",
    "            root= DATASETS_PATH / cls / \"test\",\n",
    "            transform=transforms.Compose([\n",
    "                transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "                transforms.CenterCrop(size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "            ]),\n",
    "            target_transform=transforms.Compose([\n",
    "                transforms.Resize(256, interpolation=transforms.InterpolationMode.NEAREST\n",
    "                ),\n",
    "                transforms.CenterCrop(size),\n",
    "                transforms.ToTensor(),\n",
    "            ]),\n",
    "        )\n",
    "        self.cls = cls\n",
    "        self.size = size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path, _ = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        \n",
    "        if \"good\" in path:\n",
    "            target = Image.new('L', (self.size, self.size))\n",
    "            sample_class = 0\n",
    "        else:\n",
    "            target_path = path.replace(\"test\", \"ground_truth\")\n",
    "            target_path = target_path.replace(\".png\", \"_mask.png\")\n",
    "            target = self.loader(target_path)\n",
    "            sample_class = 1\n",
    "\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return sample, target[:1], sample_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a23a6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNExtractor(torch.nn.Module):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tbackbone_name : str = \"resnet50\",\n",
    "\t\tout_indices : Tuple = None,\n",
    "\t\tpool_last : bool = False,\n",
    "\t):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.feature_extractor = timm.create_model(\n",
    "\t\t\tbackbone_name,\n",
    "\t\t\tout_indices=out_indices,\n",
    "\t\t\tfeatures_only=True,\n",
    "\t\t\tpretrained=True,\n",
    "\t\t)\n",
    "\t\tfor param in self.feature_extractor.parameters():\n",
    "\t\t\tparam.requires_grad = False\n",
    "\t\tself.feature_extractor.eval()\n",
    "\t\t\n",
    "\t\tself.pool = torch.nn.AdaptiveAvgPool2d(1) if pool_last else None\n",
    "\t\tself.backbone_name = backbone_name # for results metadata\n",
    "\t\tself.out_indices = out_indices\n",
    "\n",
    "\t\tself.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\t\tself.feature_extractor = self.feature_extractor.to(self.device)\n",
    "\t\t\t\n",
    "\tdef __call__(self, x: tensor):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfeature_maps = self.feature_extractor(x.to(self.device))\n",
    "\t\tfeature_maps = [fmap.to(\"cpu\") for fmap in feature_maps]\n",
    "\t\tif self.pool:\n",
    "\t\t\t# spit into fmaps and z\n",
    "\t\t\treturn feature_maps[:-1], self.pool(feature_maps[-1])\n",
    "\t\telse:\n",
    "\t\t\treturn feature_maps\n",
    "\n",
    "\tdef fit(self, _: DataLoader):\n",
    "\t\traise NotImplementedError\n",
    "\n",
    "\tdef predict(self, _: tensor):\n",
    "\t\traise NotImplementedError\n",
    "\n",
    "\tdef evaluate(self, test_dl: DataLoader) -> Tuple[float, float]:\n",
    "\t\t\"\"\"Calls predict step for each test sample.\"\"\"\n",
    "\t\timage_preds = []\n",
    "\t\timage_labels = []\n",
    "\t\tpixel_preds = []\n",
    "\t\tpixel_labels = []\n",
    "\n",
    "\t\tfor sample, mask, label in tqdm(test_dl, **get_tqdm_params()):\n",
    "\t\t\tz_score, fmap = self.predict(sample)\n",
    "\t\t\t\n",
    "\t\t\timage_preds.append(z_score.numpy())\n",
    "\t\t\timage_labels.append(label)\n",
    "\t\t\t\n",
    "\t\t\tpixel_preds.extend(fmap.flatten().numpy())\n",
    "\t\t\tpixel_labels.extend(mask.flatten().numpy())\n",
    "\t\t\t\n",
    "\t\timage_preds = np.stack(image_preds)\n",
    "\n",
    "\t\timage_rocauc = roc_auc_score(image_labels, image_preds)\n",
    "\t\tpixel_rocauc = roc_auc_score(pixel_labels, pixel_preds)\n",
    "\n",
    "\t\treturn image_rocauc, pixel_rocauc\n",
    "\n",
    "\tdef get_parameters(self, extra_params : dict = None) -> dict:\n",
    "\t\treturn {\n",
    "\t\t\t\"backbone_name\": self.backbone_name,\n",
    "\t\t\t\"out_indices\": self.out_indices,\n",
    "\t\t\t**extra_params,\n",
    "\t\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "061a016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPADE(KNNExtractor):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tk: int = 5,\n",
    "\t\tbackbone_name: str = \"resnet18\",\n",
    "\t):\n",
    "\t\tsuper().__init__(\n",
    "\t\t\tbackbone_name=backbone_name,\n",
    "\t\t\tout_indices=(1,2,3,-1),\n",
    "\t\t\tpool_last=True,\n",
    "\t\t)\n",
    "\t\tself.k = k\n",
    "\t\tself.image_size = 224\n",
    "\t\tself.z_lib = []\n",
    "\t\tself.feature_maps = []\n",
    "\t\tself.threshold_z = None\n",
    "\t\tself.threshold_fmaps = None\n",
    "\t\tself.blur = GaussianBlur(4)\n",
    "\n",
    "\tdef fit(self, train_dl):\n",
    "\t\tfor sample, _ in tqdm(train_dl, **get_tqdm_params()):\n",
    "\t\t\tfeature_maps, z = self(sample)\n",
    "\n",
    "\t\t\t# z vector\n",
    "\t\t\tself.z_lib.append(z)\n",
    "\n",
    "\t\t\t# feature maps\n",
    "\t\t\tif len(self.feature_maps) == 0:\n",
    "\t\t\t\tfor fmap in feature_maps:\n",
    "\t\t\t\t\tself.feature_maps.append([fmap])\n",
    "\t\t\telse:\n",
    "\t\t\t\tfor idx, fmap in enumerate(feature_maps):\n",
    "\t\t\t\t\tself.feature_maps[idx].append(fmap)\n",
    "\n",
    "\t\tself.z_lib = torch.vstack(self.z_lib)\n",
    "\t\t\n",
    "\t\tfor idx, fmap in enumerate(self.feature_maps):\n",
    "\t\t\tself.feature_maps[idx] = torch.vstack(fmap)\n",
    "\n",
    "\tdef predict(self, sample):\n",
    "\t\tfeature_maps, z = self(sample)\n",
    "\n",
    "\t\tdistances = torch.linalg.norm(self.z_lib - z, dim=1)\n",
    "\t\tvalues, indices = torch.topk(distances.squeeze(), self.k, largest=False)\n",
    "\n",
    "\t\tz_score = values.mean()\n",
    "\n",
    "\t\t# Build the feature gallery out of the k nearest neighbours.\n",
    "\t\t# The authors migh have concatenated all features maps first, then check the minimum norm per pixel.\n",
    "\t\t# Here, we check for the minimum norm first, then concatenate (sum) in the final layer.\n",
    "\t\tscaled_s_map = torch.zeros(1,1,self.image_size,self.image_size)\n",
    "\t\tfor idx, fmap in enumerate(feature_maps):\n",
    "\t\t\tnearest_fmaps = torch.index_select(self.feature_maps[idx], 0, indices)\n",
    "\t\t\t# min() because kappa=1 in the paper\n",
    "\t\t\ts_map, _ = torch.min(torch.linalg.norm(nearest_fmaps - fmap, dim=1), 0, keepdims=True)\n",
    "\t\t\tscaled_s_map += torch.nn.functional.interpolate(\n",
    "\t\t\t\ts_map.unsqueeze(0), size=(self.image_size,self.image_size), mode='bilinear'\n",
    "\t\t\t)\n",
    "\n",
    "\t\tscaled_s_map = self.blur(scaled_s_map)\n",
    "\t\t\n",
    "\t\treturn z_score, scaled_s_map\n",
    "\n",
    "\tdef get_parameters(self):\n",
    "\t\treturn super().get_parameters({\n",
    "\t\t\t\"k\": self.k,\n",
    "\t\t})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a4c52318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/wide_resnet50_racm-8234f177.pth\" to /home/akshay/.cache/torch/hub/checkpoints/wide_resnet50_racm-8234f177.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   100%|██████████| 209/209 [01:25<00:00,  2.44it/s]\n",
      "   100%|██████████| 83/83 [01:12<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "model = SPADE(\n",
    "                k=50,\n",
    "                backbone_name=\"wide_resnet50_2\",\n",
    "            )\n",
    "train_ds, test_ds = MVTecDataset(\"bottle\").get_dataloaders()\n",
    "model.fit(train_ds)\n",
    "image_rocauc, pixel_rocauc = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cdfd6c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'per_class_results': {'bottle': [0.9880952380952381, 0.9771028400474747]}, 'average image rocauc': 0.9880952380952381, 'average pixel rocauc': 0.9771028400474747, 'model parameters': {'backbone_name': 'wide_resnet50_2', 'out_indices': (1, 2, 3, -1), 'k': 50}}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "results['bottle'] = [float(image_rocauc), float(pixel_rocauc)]\n",
    "        \n",
    "image_results = [v[0] for _, v in results.items()]\n",
    "average_image_roc_auc = sum(image_results)/len(image_results)\n",
    "image_results = [v[1] for _, v in results.items()]\n",
    "average_pixel_roc_auc = sum(image_results)/len(image_results)\n",
    "\n",
    "total_results = {\n",
    "        \"per_class_results\": results,\n",
    "        \"average image rocauc\": average_image_roc_auc,\n",
    "        \"average pixel rocauc\": average_pixel_roc_auc,\n",
    "        \"model parameters\": model.get_parameters(),\n",
    "    }\n",
    "print(total_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d8720922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_lvl_anom_score, pxl_lvl_anom_score = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14295304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
