{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41ebd2ef",
   "metadata": {},
   "source": [
    "### Assignment-3\n",
    "K N Anantha nandanan\n",
    "AM.EN.U4CSE19326"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c70d74",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "882b552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from pprint import pprint\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, LsiModel\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be909d",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079a502f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18004</td>\n",
       "      <td>From: damien@b63519.student.cwru.edu (Damien N...</td>\n",
       "      <td>comp_sys_ibm_pc_hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9185</td>\n",
       "      <td>From: an030@cleveland.Freenet.Edu (Broward Hor...</td>\n",
       "      <td>talk_politics_misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8725</td>\n",
       "      <td>From: lee139@gaul.csd.uwo.ca (Steve Lee) Subje...</td>\n",
       "      <td>rec_sport_hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7805</td>\n",
       "      <td>From: dfs@doe.carleton.ca (David F. Skoll) Sub...</td>\n",
       "      <td>talk_politics_mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8592</td>\n",
       "      <td>From: cathy@LANCE.ColoState.Edu (Cathy Smith) ...</td>\n",
       "      <td>talk_politics_guns</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0       18004  From: damien@b63519.student.cwru.edu (Damien N...   \n",
       "1        9185  From: an030@cleveland.Freenet.Edu (Broward Hor...   \n",
       "2        8725  From: lee139@gaul.csd.uwo.ca (Steve Lee) Subje...   \n",
       "3        7805  From: dfs@doe.carleton.ca (David F. Skoll) Sub...   \n",
       "4        8592  From: cathy@LANCE.ColoState.Edu (Cathy Smith) ...   \n",
       "\n",
       "                 categories  \n",
       "0  comp_sys_ibm_pc_hardware  \n",
       "1        talk_politics_misc  \n",
       "2          rec_sport_hockey  \n",
       "3     talk_politics_mideast  \n",
       "4        talk_politics_guns  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../Datas/20newsgroup.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d73d318",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5f8962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(text):\n",
    "    #print(type(text))\n",
    "    stemm_snow = SnowballStemmer(\"english\")\n",
    "    lem = WordNetLemmatizer()\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = re.sub(r\"[0-9]\", \"\", text)\n",
    "    text = text.lower()\n",
    "    text = word_tokenize(text)\n",
    "    #text = [stemm_snow.stem(word) for word in text]\n",
    "    text = [lem.lemmatize(word) for word in text]\n",
    "    text = [char for char in text if char not in string.punctuation]\n",
    "    text = [word for word in text if word not in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7192bf",
   "metadata": {},
   "source": [
    "### LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2894356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(preProcessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c6797e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18004</td>\n",
       "      <td>From: damien@b63519.student.cwru.edu (Damien N...</td>\n",
       "      <td>comp_sys_ibm_pc_hardware</td>\n",
       "      <td>damien b.student.cwru.edu damien neil subject ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9185</td>\n",
       "      <td>From: an030@cleveland.Freenet.Edu (Broward Hor...</td>\n",
       "      <td>talk_politics_misc</td>\n",
       "      <td>cleveland.freenet.edu broward horne subject wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8725</td>\n",
       "      <td>From: lee139@gaul.csd.uwo.ca (Steve Lee) Subje...</td>\n",
       "      <td>rec_sport_hockey</td>\n",
       "      <td>lee gaul.csd.uwo.ca steve lee subject stop may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7805</td>\n",
       "      <td>From: dfs@doe.carleton.ca (David F. Skoll) Sub...</td>\n",
       "      <td>talk_politics_mideast</td>\n",
       "      <td>dfs doe.carleton.ca david f. skoll subject isr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8592</td>\n",
       "      <td>From: cathy@LANCE.ColoState.Edu (Cathy Smith) ...</td>\n",
       "      <td>talk_politics_guns</td>\n",
       "      <td>cathy lance.colostate.edu cathy smith subject ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0       18004  From: damien@b63519.student.cwru.edu (Damien N...   \n",
       "1        9185  From: an030@cleveland.Freenet.Edu (Broward Hor...   \n",
       "2        8725  From: lee139@gaul.csd.uwo.ca (Steve Lee) Subje...   \n",
       "3        7805  From: dfs@doe.carleton.ca (David F. Skoll) Sub...   \n",
       "4        8592  From: cathy@LANCE.ColoState.Edu (Cathy Smith) ...   \n",
       "\n",
       "                 categories                                         clean_text  \n",
       "0  comp_sys_ibm_pc_hardware  damien b.student.cwru.edu damien neil subject ...  \n",
       "1        talk_politics_misc  cleveland.freenet.edu broward horne subject wa...  \n",
       "2          rec_sport_hockey  lee gaul.csd.uwo.ca steve lee subject stop may...  \n",
       "3     talk_politics_mideast  dfs doe.carleton.ca david f. skoll subject isr...  \n",
       "4        talk_politics_guns  cathy lance.colostate.edu cathy smith subject ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b9e4874",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs =[]\n",
    "for d in df.clean_text:\n",
    "    docs.append(d.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf60e397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['damien',\n",
       " 'b.student.cwru.edu',\n",
       " 'damien',\n",
       " 'neil',\n",
       " 'subject',\n",
       " 'hot',\n",
       " 'cpu',\n",
       " 'organization',\n",
       " 'case',\n",
       " 'western',\n",
       " 'reserve',\n",
       " 'university',\n",
       " 'cleveland',\n",
       " 'ohio',\n",
       " 'usa',\n",
       " 'line',\n",
       " 'distribution',\n",
       " 'na',\n",
       " 'nntp-posting-host',\n",
       " 'b.student.cwru.edu',\n",
       " 'x-newsreader',\n",
       " 'tin',\n",
       " 'version',\n",
       " 'pl',\n",
       " 'christopher',\n",
       " 'kushmerick',\n",
       " 'kushmer',\n",
       " 'bnlux.bnl.gov',\n",
       " 'wrote',\n",
       " 'hot',\n",
       " 'cpu',\n",
       " 'dx',\n",
       " 'machine',\n",
       " 'currently',\n",
       " 'get',\n",
       " 'hot',\n",
       " 'hold',\n",
       " 'finger',\n",
       " 's.',\n",
       " 'seem',\n",
       " 'recall',\n",
       " 'run',\n",
       " 'somewhere',\n",
       " 'close',\n",
       " 'boiling',\n",
       " 'point',\n",
       " 'water',\n",
       " 'anyone',\n",
       " 'exact',\n",
       " 'temperature',\n",
       " 'anyway',\n",
       " 'putting',\n",
       " 'cpu',\n",
       " 'fan/heat',\n",
       " 'sink',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'hurt',\n",
       " 'could',\n",
       " 'help',\n",
       " 'depends',\n",
       " 'paranoid',\n",
       " '...',\n",
       " '--',\n",
       " 'damien',\n",
       " 'neil',\n",
       " 'dpn',\n",
       " 'po.cwru.edu',\n",
       " '``',\n",
       " 'someone',\n",
       " 'debugs',\n",
       " 'reality',\n",
       " 'best',\n",
       " 'case',\n",
       " 'western',\n",
       " 'reserve',\n",
       " 'university',\n",
       " 'quick',\n",
       " 'patch',\n",
       " \"''\",\n",
       " 'cmps/eeap',\n",
       " 'linux',\n",
       " '--',\n",
       " 'choice',\n",
       " 'gnu',\n",
       " 'generation',\n",
       " '-erik',\n",
       " 'green']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8f61042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the doc\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5,  keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe9e0659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2),\n",
       " (2, 2),\n",
       " (7, 1),\n",
       " (32, 1),\n",
       " (38, 1),\n",
       " (53, 1),\n",
       " (73, 1),\n",
       " (79, 1),\n",
       " (106, 1),\n",
       " (120, 1),\n",
       " (121, 1),\n",
       " (139, 1),\n",
       " (194, 2),\n",
       " (201, 1),\n",
       " (204, 1),\n",
       " (215, 1),\n",
       " (233, 1),\n",
       " (268, 1),\n",
       " (281, 1),\n",
       " (297, 1),\n",
       " (378, 1),\n",
       " (407, 1),\n",
       " (441, 1),\n",
       " (466, 1),\n",
       " (468, 1),\n",
       " (476, 1),\n",
       " (628, 1),\n",
       " (689, 1),\n",
       " (702, 1),\n",
       " (764, 1),\n",
       " (830, 1),\n",
       " (1032, 2),\n",
       " (1061, 1),\n",
       " (1108, 1),\n",
       " (1133, 1),\n",
       " (1149, 1),\n",
       " (1212, 1),\n",
       " (1331, 4),\n",
       " (1543, 1),\n",
       " (1609, 1),\n",
       " (1650, 1),\n",
       " (1672, 1),\n",
       " (1830, 1),\n",
       " (1856, 1),\n",
       " (2001, 1),\n",
       " (2063, 1),\n",
       " (2112, 1),\n",
       " (2182, 2),\n",
       " (2204, 1),\n",
       " (2265, 1),\n",
       " (2310, 1),\n",
       " (2354, 2),\n",
       " (2757, 1),\n",
       " (2808, 1),\n",
       " (2880, 1),\n",
       " (2917, 1),\n",
       " (3006, 1),\n",
       " (3010, 2),\n",
       " (3133, 1),\n",
       " (3164, 1),\n",
       " (3475, 1),\n",
       " (3645, 1),\n",
       " (3646, 1),\n",
       " (3657, 1),\n",
       " (3673, 3),\n",
       " (3891, 1),\n",
       " (3918, 1),\n",
       " (4372, 1),\n",
       " (4542, 1),\n",
       " (4945, 1),\n",
       " (5145, 1),\n",
       " (5161, 1),\n",
       " (5383, 1),\n",
       " (6107, 1),\n",
       " (6230, 1),\n",
       " (6479, 1),\n",
       " (6642, 1),\n",
       " (6647, 1),\n",
       " (8846, 1),\n",
       " (10016, 1),\n",
       " (10654, 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create the doc - Bag of Words\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "bow_corpus[4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a90a51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the LDA model\n",
    "model = LdaModel(corpus=bow_corpus, id2word=dictionary,num_topics=10, passes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38ec2d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.009*\"``\" + 0.009*\"''\" + 0.008*\"key\" + 0.008*\"space\" + 0.006*\"system\" + 0.005*\"ha\" + 0.005*\"information\" + 0.005*\"chip\" + 0.005*\"would\" + 0.004*\"clipper\"\n",
      "Topic: 1 \n",
      "Words: 0.009*\"...\" + 0.008*\"article\" + 0.008*\"wa\" + 0.008*\"would\" + 0.007*\"one\" + 0.007*\"like\" + 0.007*\"car\" + 0.007*\"get\" + 0.007*\"..\" + 0.006*\"''\"\n",
      "Topic: 2 \n",
      "Words: 0.018*\"game\" + 0.013*\"team\" + 0.010*\"israel\" + 0.008*\"wa\" + 0.008*\"...\" + 0.008*\"university\" + 0.007*\"israeli\" + 0.007*\"player\" + 0.007*\"hockey\" + 0.006*\"year\"\n",
      "Topic: 3 \n",
      "Words: 0.028*\"wa\" + 0.010*\"``\" + 0.010*\"''\" + 0.009*\"would\" + 0.007*\"one\" + 0.007*\"think\" + 0.006*\"article\" + 0.006*\"...\" + 0.006*\"know\" + 0.006*\"time\"\n",
      "Topic: 4 \n",
      "Words: 0.157*\"''\" + 0.108*\"``\" + 0.038*\"q\" + 0.035*\"p\" + 0.031*\"r\" + 0.030*\"g\" + 0.024*\"b\" + 0.023*\"w\" + 0.023*\"u\" + 0.022*\"e\"\n",
      "Topic: 5 \n",
      "Words: 0.009*\"window\" + 0.009*\"drive\" + 0.008*\"card\" + 0.008*\"system\" + 0.007*\"university\" + 0.006*\"software\" + 0.006*\"nntp-posting-host\" + 0.006*\"use\" + 0.006*\"doe\" + 0.006*\"mac\"\n",
      "Topic: 6 \n",
      "Words: 0.019*\"armenian\" + 0.016*\"``\" + 0.014*\"''\" + 0.011*\"wa\" + 0.009*\"turkish\" + 0.007*\"muslim\" + 0.007*\"_/\" + 0.007*\"jew\" + 0.006*\"university\" + 0.006*\"greek\"\n",
      "Topic: 7 \n",
      "Words: 0.032*\"x\" + 0.018*\"file\" + 0.014*\"image\" + 0.012*\"``\" + 0.010*\"''\" + 0.009*\"...\" + 0.009*\"program\" + 0.007*\"jpeg\" + 0.007*\"use\" + 0.006*\"window\"\n",
      "Topic: 8 \n",
      "Words: 0.020*\"''\" + 0.020*\"``\" + 0.010*\"wa\" + 0.009*\"people\" + 0.008*\"would\" + 0.008*\"one\" + 0.008*\"god\" + 0.005*\"ha\" + 0.005*\"doe\" + 0.005*\"say\"\n",
      "Topic: 9 \n",
      "Words: 0.009*\"``\" + 0.009*\"''\" + 0.007*\"article\" + 0.007*\"wa\" + 0.007*\"ha\" + 0.007*\"one\" + 0.006*\"cancer\" + 0.006*\"medical\" + 0.006*\"patient\" + 0.006*\"disease\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b957b612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 0 (\"''\") appears 2 time.\n",
      "Word 2 (\"``\") appears 2 time.\n",
      "Word 7 (\"case\") appears 1 time.\n",
      "Word 32 (\"nntp-posting-host\") appears 1 time.\n",
      "Word 38 (\"point\") appears 1 time.\n",
      "Word 53 (\"usa\") appears 1 time.\n",
      "Word 73 (\"oh\") appears 1 time.\n",
      "Word 79 (\"say\") appears 1 time.\n",
      "Word 106 (\"fact\") appears 1 time.\n",
      "Word 120 (\"like\") appears 1 time.\n",
      "Word 121 (\"little\") appears 1 time.\n",
      "Word 139 (\"steve\") appears 1 time.\n",
      "Word 194 (\"people\") appears 2 time.\n",
      "Word 201 (\"support\") appears 1 time.\n",
      "Word 204 (\"would\") appears 1 time.\n",
      "Word 215 (\"lot\") appears 1 time.\n",
      "Word 233 (\"find\") appears 1 time.\n",
      "Word 268 (\"fine\") appears 1 time.\n",
      "Word 281 (\"joe\") appears 1 time.\n",
      "Word 297 (\"order\") appears 1 time.\n",
      "Word 378 (\"review\") appears 1 time.\n",
      "Word 407 (\"look\") appears 1 time.\n",
      "Word 441 (\"field\") appears 1 time.\n",
      "Word 466 (\"consider\") appears 1 time.\n",
      "Word 468 (\"done\") appears 1 time.\n",
      "Word 476 (\"issue\") appears 1 time.\n",
      "Word 628 (\"communication\") appears 1 time.\n",
      "Word 689 (\"saying\") appears 1 time.\n",
      "Word 702 (\"able\") appears 1 time.\n",
      "Word 764 (\"wrong\") appears 1 time.\n",
      "Word 830 (\"wild\") appears 1 time.\n",
      "Word 1032 (\"might\") appears 2 time.\n",
      "Word 1061 (\"real\") appears 1 time.\n",
      "Word 1108 (\"chip\") appears 1 time.\n",
      "Word 1133 (\"online\") appears 1 time.\n",
      "Word 1149 (\"argument\") appears 1 time.\n",
      "Word 1212 (\"come\") appears 1 time.\n",
      "Word 1331 (\"information\") appears 4 time.\n",
      "Word 1543 (\"others\") appears 1 time.\n",
      "Word 1609 (\"yet\") appears 1 time.\n",
      "Word 1650 (\"show\") appears 1 time.\n",
      "Word 1672 (\"perspective\") appears 1 time.\n",
      "Word 1830 (\"put\") appears 1 time.\n",
      "Word 1856 (\"top\") appears 1 time.\n",
      "Word 2001 (\"access\") appears 1 time.\n",
      "Word 2063 (\"doubt\") appears 1 time.\n",
      "Word 2112 (\"likely\") appears 1 time.\n",
      "Word 2182 (\"side\") appears 2 time.\n",
      "Word 2204 (\"turn\") appears 1 time.\n",
      "Word 2265 (\"design\") appears 1 time.\n",
      "Word 2310 (\"solid\") appears 1 time.\n",
      "Word 2354 (\"government\") appears 2 time.\n",
      "Word 2757 (\"fear\") appears 1 time.\n",
      "Word 2808 (\"hide\") appears 1 time.\n",
      "Word 2880 (\"making\") appears 1 time.\n",
      "Word 2917 (\"official\") appears 1 time.\n",
      "Word 3006 (\"save\") appears 1 time.\n",
      "Word 3010 (\"secret\") appears 2 time.\n",
      "Word 3133 (\"urge\") appears 1 time.\n",
      "Word 3164 (\"debate\") appears 1 time.\n",
      "Word 3475 (\"term\") appears 1 time.\n",
      "Word 3645 (\"access.digex.com\") appears 1 time.\n",
      "Word 3646 (\"access.digex.net\") appears 1 time.\n",
      "Word 3657 (\"clipper\") appears 1 time.\n",
      "Word 3673 (\"fed\") appears 3 time.\n",
      "Word 3891 (\"suspicion\") appears 1 time.\n",
      "Word 3918 (\"md\") appears 1 time.\n",
      "Word 4372 (\"stamp\") appears 1 time.\n",
      "Word 4542 (\"prove\") appears 1 time.\n",
      "Word 4945 (\"judgment\") appears 1 time.\n",
      "Word 5145 (\"accurate\") appears 1 time.\n",
      "Word 5161 (\"greenbelt\") appears 1 time.\n",
      "Word 5383 (\"express\") appears 1 time.\n",
      "Word 6107 (\"speculation\") appears 1 time.\n",
      "Word 6230 (\"constitutional\") appears 1 time.\n",
      "Word 6479 (\"swiss\") appears 1 time.\n",
      "Word 6642 (\"brinich\") appears 1 time.\n",
      "Word 6647 (\"steve-b\") appears 1 time.\n",
      "Word 8846 (\"uncertainty\") appears 1 time.\n",
      "Word 10016 (\"secrecy\") appears 1 time.\n",
      "Word 10654 (\"cheese\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4000 = bow_corpus[4000]\n",
    "for i in range(len(bow_doc_4000)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4000[i][0], \n",
    "                                               dictionary[bow_doc_4000[i][0]], \n",
    "bow_doc_4000[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f580dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.40468040108680725\t \n",
      "Topic: 0.020*\"''\" + 0.020*\"``\" + 0.010*\"wa\" + 0.009*\"people\" + 0.008*\"would\" + 0.008*\"one\" + 0.008*\"god\" + 0.005*\"ha\" + 0.005*\"doe\" + 0.005*\"say\"\n",
      "\n",
      "Score: 0.3124648928642273\t \n",
      "Topic: 0.009*\"``\" + 0.009*\"''\" + 0.008*\"key\" + 0.008*\"space\" + 0.006*\"system\" + 0.005*\"ha\" + 0.005*\"information\" + 0.005*\"chip\" + 0.005*\"would\" + 0.004*\"clipper\"\n",
      "\n",
      "Score: 0.20847144722938538\t \n",
      "Topic: 0.009*\"``\" + 0.009*\"''\" + 0.007*\"article\" + 0.007*\"wa\" + 0.007*\"ha\" + 0.007*\"one\" + 0.006*\"cancer\" + 0.006*\"medical\" + 0.006*\"patient\" + 0.006*\"disease\"\n",
      "\n",
      "Score: 0.06799325346946716\t \n",
      "Topic: 0.009*\"...\" + 0.008*\"article\" + 0.008*\"wa\" + 0.008*\"would\" + 0.007*\"one\" + 0.007*\"like\" + 0.007*\"car\" + 0.007*\"get\" + 0.007*\"..\" + 0.006*\"''\"\n"
     ]
    }
   ],
   "source": [
    "## Docuement 4000 of the Dataset is classified as such\n",
    "for index, score in sorted(model[bow_corpus[4000]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc47fad2",
   "metadata": {},
   "source": [
    "### KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e624e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.clean_text\n",
    "tfidf_vectoriser = TfidfVectorizer()\n",
    "X = tfidf_vectoriser.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d83e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = set(df.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9297b907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt_atheism',\n",
       " 'comp_graphics',\n",
       " 'comp_os_ms-windows_misc',\n",
       " 'comp_sys_ibm_pc_hardware',\n",
       " 'comp_sys_mac_hardware',\n",
       " 'comp_windows_x',\n",
       " 'misc_forsale',\n",
       " 'rec_autos',\n",
       " 'rec_motorcycles',\n",
       " 'rec_sport_baseball',\n",
       " 'rec_sport_hockey',\n",
       " 'sci_crypt',\n",
       " 'sci_electronics',\n",
       " 'sci_med',\n",
       " 'sci_space',\n",
       " 'soc_religion_christian',\n",
       " 'talk_politics_guns',\n",
       " 'talk_politics_mideast',\n",
       " 'talk_politics_misc',\n",
       " 'talk_religion_misc'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34b435ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        comp_sys_ibm_pc_hardware\n",
       "1              talk_politics_misc\n",
       "2                rec_sport_hockey\n",
       "3           talk_politics_mideast\n",
       "4              talk_politics_guns\n",
       "                   ...           \n",
       "18841       talk_politics_mideast\n",
       "18842             rec_motorcycles\n",
       "18843            rec_sport_hockey\n",
       "18844                   rec_autos\n",
       "18845               comp_graphics\n",
       "Name: categories, Length: 18846, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df.categories\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "733c9160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 18, 10, ..., 10,  7,  1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_Y = LabelEncoder()\n",
    "Y = label_Y.fit_transform(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94ffeed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 121331) (18846,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad65cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c3d1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c929b24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137.2807342637706"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = np.sqrt(N)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f7a1fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=137)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=137)\n",
    "knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c884c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "61cb7e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.84      0.75       154\n",
      "           1       0.75      0.69      0.72       198\n",
      "           2       0.67      0.73      0.70       203\n",
      "           3       0.58      0.71      0.64       201\n",
      "           4       0.70      0.62      0.66       204\n",
      "           5       0.89      0.69      0.78       196\n",
      "           6       0.84      0.56      0.67       204\n",
      "           7       0.81      0.86      0.84       190\n",
      "           8       0.80      0.88      0.84       193\n",
      "           9       0.91      0.86      0.89       213\n",
      "          10       0.76      0.98      0.86       196\n",
      "          11       0.81      0.91      0.85       200\n",
      "          12       0.87      0.51      0.64       212\n",
      "          13       0.93      0.77      0.84       188\n",
      "          14       0.75      0.90      0.82       183\n",
      "          15       0.75      0.92      0.83       206\n",
      "          16       0.70      0.91      0.79       183\n",
      "          17       0.85      0.97      0.91       166\n",
      "          18       0.80      0.71      0.75       158\n",
      "          19       0.80      0.32      0.46       122\n",
      "\n",
      "    accuracy                           0.77      3770\n",
      "   macro avg       0.78      0.77      0.76      3770\n",
      "weighted avg       0.78      0.77      0.77      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Report\n",
    "print(classification_report(Y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0cc48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
