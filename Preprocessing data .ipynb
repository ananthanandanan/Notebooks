{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87511dd6",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a76dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer # used for handling missing data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # used for encoding categorical data\n",
    "from sklearn.model_selection import train_test_split # used for splitting training and testing data\n",
    "from sklearn.preprocessing import StandardScaler # used for feature scaling\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1afa0d",
   "metadata": {},
   "source": [
    "### import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1dfbffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Region   Age   Income Online Shopper\n",
      "0   India  49.0  86400.0             No\n",
      "1  Brazil  32.0  57600.0            Yes\n",
      "2     USA  35.0  64800.0             No\n",
      "3  Brazil  43.0  73200.0             No\n",
      "4     USA  45.0      NaN            Yes\n",
      "5   India  40.0  69600.0            Yes\n",
      "6  Brazil   NaN  62400.0             No\n",
      "7   India  53.0  94800.0            Yes\n",
      "8     USA  55.0  99600.0             No\n",
      "9   India  42.0  80400.0            Yes\n",
      "[['India' 49.0 86400.0]\n",
      " ['Brazil' 32.0 57600.0]\n",
      " ['USA' 35.0 64800.0]\n",
      " ['Brazil' 43.0 73200.0]\n",
      " ['USA' 45.0 nan]\n",
      " ['India' 40.0 69600.0]\n",
      " ['Brazil' nan 62400.0]\n",
      " ['India' 53.0 94800.0]\n",
      " ['USA' 55.0 99600.0]\n",
      " ['India' 42.0 80400.0]]\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Data.csv')\n",
    "# Splitting the attributes into independent and dependent attributes\n",
    "X = dataset.iloc[:, :-1].values # attributes to determine dependent variable / Class\n",
    "Y = dataset.iloc[:, -1].values # dependent variable / Class\n",
    "print(dataset)\n",
    "print(X)\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1746b7bb",
   "metadata": {},
   "source": [
    "### Handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02810365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['India' 49.0 86400.0]\n",
      " ['Brazil' 32.0 57600.0]\n",
      " ['USA' 35.0 64800.0]\n",
      " ['Brazil' 43.0 73200.0]\n",
      " ['USA' 45.0 76533.33333333333]\n",
      " ['India' 40.0 69600.0]\n",
      " ['Brazil' 43.77777777777778 62400.0]\n",
      " ['India' 53.0 94800.0]\n",
      " ['USA' 55.0 99600.0]\n",
      " ['India' 42.0 80400.0]]\n"
     ]
    }
   ],
   "source": [
    "# handling the missing data and replace missing values with nan from numpy and replace with mean of all the other values\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean') \n",
    "imputer = imputer.fit(X[:, 1:])\n",
    "X[:, 1:] = imputer.transform(X[:, 1:])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3076e7b5",
   "metadata": {},
   "source": [
    "### encode categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "249efd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= [[0.0 1.0 0.0 1.0 0.0 49.0 86400.0]\n",
      " [1.0 0.0 1.0 0.0 0.0 32.0 57600.0]\n",
      " [0.0 1.0 0.0 0.0 1.0 35.0 64800.0]\n",
      " [1.0 0.0 1.0 0.0 0.0 43.0 73200.0]\n",
      " [0.0 1.0 0.0 0.0 1.0 45.0 76533.33333333333]\n",
      " [0.0 1.0 0.0 1.0 0.0 40.0 69600.0]\n",
      " [1.0 0.0 1.0 0.0 0.0 43.77777777777778 62400.0]\n",
      " [0.0 1.0 0.0 1.0 0.0 53.0 94800.0]\n",
      " [0.0 1.0 0.0 0.0 1.0 55.0 99600.0]\n",
      " [0.0 1.0 0.0 1.0 0.0 42.0 80400.0]]\n",
      "Y= [0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# encode categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
    "X = columnTransformer.fit_transform(X)\n",
    "print('X=', X)\n",
    "labelencoder_Y = LabelEncoder()\n",
    "Y = labelencoder_Y.fit_transform(Y)\n",
    "print('Y=', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bfec05",
   "metadata": {},
   "source": [
    "### training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3965681c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 0.0 1.0 35.0 64800.0]\n",
      " [0.0 1.0 0.0 0.0 1.0 55.0 99600.0]]\n",
      "[0 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>64800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>99600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4     5        6\n",
       "0  0.0  1.0  0.0  0.0  1.0  35.0  64800.0\n",
       "1  0.0  1.0  0.0  0.0  1.0  55.0  99600.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the dataset into training set and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "print(X_test)\n",
    "print(Y_test)\n",
    "test = pd.DataFrame(X_test)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ec18a9",
   "metadata": {},
   "source": [
    "### feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eee9513",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-38df94090091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msc_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx_df_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# feature scaling\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "x_df_train = pd.DataFrame(X_train)\n",
    "x_df_train\n",
    "x_df_test = pd.DataFrame(X_test)\n",
    "x_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8500c94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
